# -*- coding: utf-8 -*-
"""
ModuÅ‚ RAG - Retrieval-Augmented Generation
===========================================

Ten moduÅ‚ zapewnia dostÄ™p do bazy wiedzy z dokumentacji podczas runtime.
UÅ¼ywany przez VirtualAssistant do wzbogacenia kontekstu o informacje z dokumentacji.

FunkcjonalnoÅ›Ä‡:
- Wyszukiwanie semantyczne w bazie wiedzy
- Zwracanie najbardziej relevantnych fragmentÃ³w dokumentacji
- Optymalizacja pod kÄ…tem polskiego jÄ™zyka
"""

from pathlib import Path
from typing import List, Dict, Optional, Any
import chromadb  # type: ignore
from sentence_transformers import SentenceTransformer  # type: ignore


class RAGKnowledgeBase:
    """
    Klasa do wyszukiwania w bazie wiedzy RAG
    
    UÅ¼ywa ChromaDB i sentence-transformers do semantycznego wyszukiwania
    w dokumentacji systemu.
    """
    
    # Model embedingowy - ten sam co uÅ¼yty do budowy bazy
    EMBEDDING_MODEL = "sdadas/mmlw-retrieval-roberta-large"
    
    # Nazwa kolekcji w ChromaDB
    COLLECTION_NAME = "knowledge_base"
    
    def __init__(self, db_path: Optional[str] = None):
        """
        Inicjalizacja bazy wiedzy RAG
        
        Args:
            db_path: ÅšcieÅ¼ka do folderu z bazÄ… ChromaDB (opcjonalne)
                    JeÅ›li None, uÅ¼yje domyÅ›lnej lokalizacji
        """
        self.initialized = False
        self.embedding_model = None
        self.collection = None
        
        # Ustal Å›cieÅ¼kÄ™ do bazy
        if db_path is None:
            current_dir = Path(__file__).parent
            db_path = current_dir / "chroma_db"
        else:
            db_path = Path(db_path)
        
        self.db_path = db_path
        
        # SprawdÅº czy baza istnieje
        if not self.db_path.exists():
            print(f"âš ï¸  Baza wiedzy RAG nie istnieje: {self.db_path}")
            print("ğŸ’¡ Uruchom: python build_rag_database.py aby jÄ… utworzyÄ‡")
            return
        
        try:
            self._initialize()
        except Exception as e:
            print(f"âš ï¸  BÅ‚Ä…d inicjalizacji bazy wiedzy RAG: {e}")
            print("ğŸ’¡ System bÄ™dzie dziaÅ‚aÄ‡ bez bazy wiedzy")
    
    def _initialize(self):
        """Inicjalizuje model i poÅ‚Ä…czenie z bazÄ…"""
        # ZaÅ‚aduj model embedingowy
        self.embedding_model = SentenceTransformer(self.EMBEDDING_MODEL)
        
        # PoÅ‚Ä…cz z ChromaDB
        self.client = chromadb.PersistentClient(path=str(self.db_path))
        
        # ZaÅ‚aduj kolekcjÄ™
        try:
            self.collection = self.client.get_collection(self.COLLECTION_NAME)
            self.initialized = True
            print(f"âœ… Baza wiedzy RAG zaÅ‚adowana: {self.collection.count()} dokumentÃ³w")
        except Exception as e:
            raise Exception(f"Nie moÅ¼na zaÅ‚adowaÄ‡ kolekcji '{self.COLLECTION_NAME}': {e}")
    
    def is_available(self) -> bool:
        """
        Sprawdza czy baza wiedzy jest dostÄ™pna
        
        Returns:
            True jeÅ›li baza jest zainicjalizowana i gotowa
        """
        return self.initialized
    
    def search(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        """
        Wyszukuje najbardziej relevantne fragmenty dokumentacji
        
        Args:
            query: Zapytanie uÅ¼ytkownika (w jÄ™zyku naturalnym)
            top_k: Liczba wynikÃ³w do zwrÃ³cenia (domyÅ›lnie 3)
            
        Returns:
            Lista sÅ‚ownikÃ³w z wynikami:
            [
                {
                    'text': 'TreÅ›Ä‡ fragmentu dokumentacji',
                    'filename': 'nazwa_pliku.md',
                    'chunk_index': 0,
                    'distance': 0.234  # im mniejsza tym lepsze dopasowanie
                },
                ...
            ]
        """
        if not self.initialized:
            return []
        
        try:
            # Wygeneruj embedding dla zapytania
            query_embedding = self.embedding_model.encode([query])[0].tolist()
            
            # Wyszukaj w bazie
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=top_k,
                include=['documents', 'metadatas', 'distances']
            )
            
            # Formatuj wyniki
            formatted_results = []
            if results['documents'] and len(results['documents'][0]) > 0:
                for i in range(len(results['documents'][0])):
                    formatted_results.append({
                        'text': results['documents'][0][i],
                        'filename': results['metadatas'][0][i]['filename'],
                        'chunk_index': results['metadatas'][0][i]['chunk_index'],
                        'source_path': results['metadatas'][0][i]['source_path'],
                        'distance': results['distances'][0][i]
                    })
            
            return formatted_results
            
        except Exception as e:
            print(f"âš ï¸  BÅ‚Ä…d wyszukiwania w bazie RAG: {e}")
            return []
    
    def get_context_for_query(self, query: str, max_tokens: int = 2000) -> str:
        """
        Zwraca sformatowany kontekst z bazy wiedzy dla danego zapytania
        
        Args:
            query: Zapytanie uÅ¼ytkownika
            max_tokens: Maksymalna dÅ‚ugoÅ›Ä‡ kontekstu (w przybliÅ¼eniu znaki/4)
            
        Returns:
            Sformatowany string z kontekstem do dodania do prompta
        """
        if not self.initialized:
            return ""
        
        results = self.search(query, top_k=3)
        
        if not results:
            return ""
        
        # Buduj kontekst z wynikÃ³w
        context_parts = ["=== KONTEKST Z BAZY WIEDZY ===\n"]
        current_length = len(context_parts[0])
        
        for i, result in enumerate(results, 1):
            # Formatuj fragment
            fragment = f"\nğŸ“„ Å¹rÃ³dÅ‚o: {result['filename']}\n"
            fragment += f"{result['text']}\n"
            fragment += "-" * 50 + "\n"
            
            # SprawdÅº czy nie przekroczymy limitu
            if current_length + len(fragment) > max_tokens * 4:
                break
            
            context_parts.append(fragment)
            current_length += len(fragment)
        
        context_parts.append("\n=== KONIEC KONTEKSTU ===\n")
        
        return "".join(context_parts)
    
    def search_specific_topic(self, topic: str) -> List[Dict[str, Any]]:
        """
        Wyszukuje fragmenty dotyczÄ…ce konkretnego tematu
        
        Args:
            topic: Temat do wyszukania (np. "architektura", "API", "narzÄ™dzia")
            
        Returns:
            Lista wynikÃ³w jak w metodzie search()
        """
        # Rozszerz zapytanie dla lepszych wynikÃ³w
        expanded_query = f"Dokumentacja techniczna: {topic}. Opis i wyjaÅ›nienie."
        return self.search(expanded_query, top_k=5)
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        Zwraca statystyki bazy wiedzy
        
        Returns:
            SÅ‚ownik ze statystykami
        """
        if not self.initialized:
            return {
                'available': False,
                'error': 'Baza nie zostaÅ‚a zainicjalizowana'
            }
        
        return {
            'available': True,
            'total_chunks': self.collection.count(),
            'collection_name': self.COLLECTION_NAME,
            'embedding_model': self.EMBEDDING_MODEL,
            'db_path': str(self.db_path)
        }


# Singleton instance - moÅ¼e byÄ‡ uÅ¼ywana globalnie
_global_rag_instance: Optional[RAGKnowledgeBase] = None


def get_rag_knowledge_base() -> RAGKnowledgeBase:
    """
    Zwraca globalnÄ… instancjÄ™ bazy wiedzy RAG (singleton)
    
    Returns:
        RAGKnowledgeBase instance
    """
    global _global_rag_instance
    
    if _global_rag_instance is None:
        _global_rag_instance = RAGKnowledgeBase()
    
    return _global_rag_instance


def reset_rag_knowledge_base():
    """Resetuje globalnÄ… instancjÄ™ (przydatne przy testach)"""
    global _global_rag_instance
    _global_rag_instance = None
